{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting propagate.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile propagate.py\n",
    "import numpy as np \n",
    "\n",
    "class affine_function: \n",
    "    \n",
    "    def __init__(self): \n",
    "        self.w, self.b = None, None \n",
    "        self.y_hat = None \n",
    "    \n",
    "    def forward(self, w, b, x): \n",
    "        self.w, self.b, self.x = w, b, x  \n",
    "        self.y_hat = np.dot(self.w.T, self.x) + self.b\n",
    "        return self.y_hat \n",
    "    \n",
    "    def backward(self, dvoi):  \n",
    "        self.dw = np.dot(dvoi, self.x.T) \n",
    "        \n",
    "        self.db = np.ones((self.x.shape[1],1))\n",
    "        self.db = np.dot(dvoi,self.db) \n",
    "        return self.dw, self.db \n",
    "\n",
    "class loss_function: \n",
    "    \n",
    "    def __init__(self): \n",
    "        self.y, self.y_hat = None, None \n",
    "        self.loss = None \n",
    "    \n",
    "    def forward(self, y, y_hat): \n",
    "        self.y, self.y_hat = y, y_hat \n",
    "        self.loss = (self.y - self.y_hat)**2 \n",
    "        return self.loss \n",
    "    \n",
    "    def backward(self, dvoi): \n",
    "        self.dy_hat = -2 * (self.y - self.y_hat)\n",
    "        self.dy_hat = np.diag(self.dy_hat[0])\n",
    "        self.dy_hat = np.dot(dvoi,self.dy_hat)\n",
    "        return self.dy_hat\n",
    "\n",
    "class cost_function: \n",
    "    def __init__(self): \n",
    "        self.loss = None \n",
    "        self.cost = None \n",
    "        \n",
    "    def forward(self, loss): \n",
    "        self.loss = loss \n",
    "        self.cost = np.mean(loss)\n",
    "        return self.cost \n",
    "    \n",
    "    def backward(self, sample_size, dvoi): \n",
    "        self.dloss = 1/sample_size * np.ones((1,sample_size))\n",
    "        self.dloss = dvoi * self.dloss\n",
    "        return self.dloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import propagate\n",
    "\n",
    "affine = propagate.affine_function()\n",
    "loss = propagate.loss_function()\n",
    "cost = propagate.cost_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_update = []\n",
    "bias_update = [] \n",
    "cost_update = [] \n",
    "\n",
    "for i in range(0,5): \n",
    "    #shuffle columns(samples) of X \n",
    "    x, y = X, Y \n",
    "    \n",
    "    y_hat = affine.forward(weight, bias, x)\n",
    "    L = loss.forward(y, y_hat)\n",
    "    J = cost.forward(L)\n",
    "            \n",
    "    dL = cost.backward(sample_size = m_samples, dvoi=1)\n",
    "    dy_hat = loss.backward(dL)\n",
    "    dw, db = affine.backward(dy_hat)\n",
    "            \n",
    "    dw, db = np.sum(dw), np.sum(db)\n",
    "            \n",
    "    weight -= lr*dw \n",
    "    bias -= lr*db\n",
    "            \n",
    "    weight_update.append(weight)\n",
    "    bias_update.append(bias)\n",
    "    cost_update.append(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([[153.7309987]]),\n",
       "  array([[153.7309987]]),\n",
       "  array([[153.7309987]]),\n",
       "  array([[153.7309987]]),\n",
       "  array([[153.7309987]])],\n",
       " [array([22.05367743]),\n",
       "  array([22.05367743]),\n",
       "  array([22.05367743]),\n",
       "  array([22.05367743]),\n",
       "  array([22.05367743])],\n",
       " [<propagate.cost_function at 0x1ae6249bd88>,\n",
       "  <propagate.cost_function at 0x1ae6249bd88>,\n",
       "  <propagate.cost_function at 0x1ae6249bd88>,\n",
       "  <propagate.cost_function at 0x1ae6249bd88>,\n",
       "  <propagate.cost_function at 0x1ae6249bd88>])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_update, bias_update, cost_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[91.99189311 92.08027778 92.16866245 92.25704713 92.3454318  92.43381647\n",
      "  92.52220115 92.61058582 92.69897049 92.78735516]]\n",
      "[[8522.69342488 8447.59147284 8613.09446882 8349.2420583  8555.04948094\n",
      "  8254.67006481 8341.56231435 8512.25135682 8914.32210568 8702.36771465]]\n",
      "8521.284446207592\n",
      "[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n",
      "[[18.46368698 18.38215599 18.56135175 18.27483741 18.4987021  18.17104297\n",
      "  18.26643076 18.45237259 18.88313756 18.65729639]]\n",
      "91404.2100812961 184.61101449965878\n",
      "[[-4569.49824409]\n",
      " [-4570.2548371 ]\n",
      " [-4569.85642111]\n",
      " [-4572.21857485]\n",
      " [-4570.41318805]\n",
      " [-4570.94641684]\n",
      " [-4571.41261444]\n",
      " [-4569.48605842]\n",
      " [-4569.07827409]\n",
      " [-4568.85202697]] [-10.15777261]\n"
     ]
    }
   ],
   "source": [
    "x, y = X, Y \n",
    "    \n",
    "y_hat = affine.forward(weight, bias, x)\n",
    "print(y_hat)\n",
    "L = loss.forward(y, y_hat)\n",
    "print(L)\n",
    "J = cost.forward(L)\n",
    "print(J)\n",
    "            \n",
    "dL = cost.backward(sample_size = m_samples, dvoi=1)\n",
    "print(dL)\n",
    "dy_hat = loss.backward(dL)\n",
    "print(dy_hat)\n",
    "dw, db = affine.backward(dy_hat)\n",
    "            \n",
    "dw, db = np.sum(dw), np.sum(db)\n",
    "print(dw,db)\n",
    "            \n",
    "weight -= lr*dw \n",
    "bias -= lr*db\n",
    "print(weight,bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
